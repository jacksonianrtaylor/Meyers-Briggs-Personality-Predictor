#ways to normalize...
#ttps://www.digitalocean.com/community/tutorials/normalize-data-in-python


# X = csr_matrix(X)
# X = normalize(X, norm = "l2", axis = 0)
# X = csc_matrix(X)
# efficient row slicing...
# good for removing samples...
# this is required when using normalization

#try minmax scaler...
#this might work better than scaling unit norm
#https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler.fit_transform

#min max scalar:
# scaler = MinMaxScaler()
# X = scaler.fit_transform(X)

# try: normalizing about samples or features...
# if X is normalized about samples
# if X is normalized about the features
# no normalization was found to be the most effective...
# should try different seeds tho
# tutorial
# https://www.digitalocean.com/community/tutorials/normalize-data-in-python
# question (is row normalization good for counts?) answer (yes)
# https://stackoverflow.com/questions/60275133/difference-between-row-and-column-normalization#:~:text=Column%20normalization%20is%20more%20prevalent,faster%20while%20used%20in%20deeplearning.


#https://stats.stackexchange.com/questions/82726/is-normalizing-the-features-always-good-for-classification

#efficient column slicing...
#good for removing features...
#like used in select k best...


#or
# scalar = StandardScaler()
# X = scalar.fit_transform(X)

#try minmax scaler...
#this might work better than scaling unit norm
#https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler.fit_transform
